{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "MPS 장치를 지원하도록 build가 되었는가? True\n",
      "MPS 장치가 사용 가능한가? True\n",
      "사용 디바이스: mps\n",
      "tensor([[0.6418, 0.9082, 0.3853],\n",
      "        [0.1920, 0.6369, 0.7768],\n",
      "        [0.3782, 0.3077, 0.8622],\n",
      "        [0.3065, 0.7926, 0.2575],\n",
      "        [0.8374, 0.7644, 0.8989]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import torchinfo, torchmetrics\n",
    "\n",
    "# Check PyTorch access (should print out a tensor)\n",
    "# print(torch.randn(3, 3))\n",
    "\n",
    "# Check for GPU (should return True)\n",
    "# print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.__version__)\n",
    "print(f\"MPS 장치를 지원하도록 build가 되었는가? {torch.backends.mps.is_built()}\")\n",
    "print(f\"MPS 장치가 사용 가능한가? {torch.backends.mps.is_available()}\") \n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "\n",
    "\n",
    "e = torch.rand(5, 3)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "### 1. Creating Tensors\n",
    "Pytorch tensors are created using`torch.tensor() = https://pytorch.org/docs/stable/tensors.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "########## SCALAR\n",
      "tensor(7)\n",
      "0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# scalar\n",
    "print(\"\\n\\n########## SCALAR\")\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "print(scalar.ndim) # scalar의 차원\n",
    "\n",
    "# Get tensor back as Python int\n",
    "print(scalar.item()) # scalar의 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "########## VECTOR\n",
      "tensor([7, 7])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "print(vector)\n",
    "print(vector.ndim) # vector의 차원\n",
    "print(vector.shape) # vector의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "2\n",
      "tensor([ 9, 10])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim) # matrix의 차원\n",
    "print(MATRIX[1])\n",
    "print(MATRIX.shape) # matrix의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [3, 6, 9],\n",
      "         [3, 5, 4]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3,],\n",
    "                        [3,6,9,],\n",
    "                        [3,5,4]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim) # tensor의 차원\n",
    "print(TENSOR.shape) # tensor의 크기\n",
    "print(TENSOR[0][0]) # 0번째 텐서의 0번째 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "#### Why Random Tensors?\n",
    "- Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "- 데이터 분석 및 모델 테스트를 위해 무작위 데이터를 생성하는 것이 중요.\n",
    "- 무작위 데이터를 생성하면 모델이 데이터를 학습하고 예측하는 능력을 평가할 수 있음.\n",
    "\n",
    "`start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "########## RANDOM TENSORS\n",
      "tensor([[[0.1384, 0.2180, 0.6383, 0.4042],\n",
      "         [0.1864, 0.4526, 0.3141, 0.4745],\n",
      "         [0.5441, 0.7380, 0.3949, 0.8289]]])\n",
      "3\n",
      "torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n########## RANDOM TENSORS\")\n",
    "\n",
    "#Create random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(1, 3, 4)\n",
    "print(random_tensor)\n",
    "print(random_tensor.ndim)# 텐서의 차원\n",
    "print(random_tensor.shape)# 텐서의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3]) 3\n"
     ]
    }
   ],
   "source": [
    "# Create random tensor with similar shape to an image\n",
    "random_image_size_tensor = torch.rand(224, 224, 3) # 높이, 너비, 색상 채널\n",
    "print(random_image_size_tensor.shape, random_image_size_tensor.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerps and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones \n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range() and get deprecated message, use torch.arange() instead\n",
    "one_to_ten = torch.arange(start=1, end=1000, step=77) # 1부터 1000까지 77씩 증가하는 텐서\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1) # 1부터 10까지 1씩 증가하는 텐서\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor data types\n",
    "\n",
    "**Note** : Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning.\n",
    "\n",
    "1. Tensors not data types\n",
    "2. Tensors not device\n",
    "3. Tensors not shape\n",
    "\n",
    "\n",
    "Precision in computing = 데이터의 정밀도\n",
    "https://en.wikipedia.org/wiki/Precision_(computer_science)\n",
    "\n",
    "> 데이터 타입, 장치, 형태를 관리하는 것은 PyTorch에서 딥 러닝 모델 작성 시 필수적인 작업입니다.\n",
    "\n",
    "#### 데이터 타입의 종류\n",
    "- PyTorch에서 지원하는 주요 데이터 타입:\n",
    "\t- float16, float32, float64: 부동 소수점 숫자.\n",
    "\t- int8, int16, int32, int64: 정수.\n",
    "\t- bool: 논리값.\n",
    "\t- complex32, complex64: 복소수.\n",
    "- 데이터 타입은 정밀도와 메모리 사용량에 영향을 미칩니다.\n",
    "\t- float16: 더 적은 메모리를 사용하며 연산 속도가 빠르지만, 정밀도가 낮습니다.\n",
    "\t- float32: 기본 데이터 타입으로, 적당한 정밀도와 메모리 사용량을 가집니다.\n",
    "\t- float64: 높은 정밀도와 더 많은 메모리 사용량.\n",
    "\n",
    "#### 데이터 타입 선택의 중요성\n",
    "- 정밀도:\n",
    "\t- float16: 메모리 절약 및 빠른 계산이 필요한 경우.\n",
    "\t- float32: 일반적인 상황에서 사용.\n",
    "\t- float64: 높은 정밀도가 필요한 경우.\n",
    "- 메모리 및 성능:\n",
    "\t- 더 낮은 비트 수의 데이터 타입(float16)은 더 적은 메모리를 사용하고 계산 속도가 빠름.\n",
    "\n",
    "#### 실수할 수 있는 주요 문제\n",
    "1.\t데이터 타입 불일치:\n",
    "\t- 서로 다른 데이터 타입의 텐서로 연산을 시도할 경우 오류 발생.\n",
    "2.\t장치 불일치:\n",
    "\t- 텐서가 CPU와 GPU에 각각 위치할 경우 연산 불가능.\n",
    "\t- 동일한 장치로 이동 필요:\n",
    "3.\t형태 불일치:\n",
    "\t- 텐서의 차원이나 크기가 다르면 연산 불가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True], device='mps:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor \n",
    "# 단일 정밀도\n",
    "# 대부분의 경우 32비트 정밀도를 사용하는 것이 좋음.\n",
    "# 메모리를 많이 사용하지만 정밀도가 높음.(더 정밀한 작업이 필요한 경우 64비트 정밀도를 사용)\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=torch.float32, # 데이터 타입을 지정하고 싶다면 dtype 매개변수를 사용 | What datatype is the tensor(e.g. float32 or float16) - 부동 소수점, 정수, 복소수 등 선택 가능.\n",
    "                               device=\"mps\", # 텐서가 위치할 장치('cuda(gpu)', 'mps', 'cpu') | What device is your tensor on?\n",
    "                               requires_grad=False # 텐서의 그래디언트를 추적할지 여부. | 기본값은 False, 역전파 계산에 필요할 경우 True로 설정.\n",
    "                               )\n",
    "\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 16 tensor\n",
    "# 하프 플로트 타입은 메모리를 절반으로 줄이고 속도를 높일 수 있음.\n",
    "# 정밀도가 낮음.\n",
    "# float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
    "# float_16_tensor\n",
    "\n",
    "float_16_tensor = float_32_tensor.to(torch.half)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], device='mps:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
